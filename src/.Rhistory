rlnorm(1, alpha.x, sqrt(tauS.x))
}
#------------------------------------------------
# Retweet graph conditional posteriors ***********
#------------------------------------------------
post_beta = function(sigmaS.b, b){
# The conditional joint posterior of the three betas.
# The follow a multivariate normal distribution with parameters mu and C
# as defined below.
N1 = N + sigmaS.b * sigma.beta^(-2)
E = sum(log(f+1)*log(d+1))
D = sum(log(d+1))
D2 = sum(log(d+1)^2) + sigmaS.b * sigma.beta^(-2)
W = sum(log(f+1))
W2 = sum(log(f+1)^2) + sigmaS.b * sigma.beta^(-2)
Y0 = sum(log(b+1))
YF = sum(log(b+1)*log(f+1))
Yd = sum((log(b+1)^2)*log(d+1)) + sigmaS.b * sigma.beta^(-2)
C = matrix(c(
N1, W, D,
W, W2, E,
D, E, D2),nrow=3,byrow = TRUE)
C = sigmaS.b * solve(C)
mu = C %*% t(c(Y0, YF, Yd))
return(rmvnorm(1, mu, C))
}
post_sigmaS.b = function(b, beta){
ad = a.sigma.b + N/2
mu = c()
for(i in 1:N){
mu = c(mu, mu.j.x(beta, f[i],d[i]))
}
bd = b.sigma.b + .5 * sum( (logit(b)-mu)^2)
return(rinvgauss(1, ad, bd))
}
# Note: b.j.x is sample by MH
# the posterior of it returns a density instead of a sample.
# the sample is taken from the proposal
post_b.j.x = function(x, f.j.x, b.j.x, d.j.x, beta, sigmaS.b){
mu = mu.j.x(beta, f.j.x, d.j.x)
den =  dbinom(x,f.j.x,b.j.x) *  dlogitnorm(x, mu,sqrt(sigmaS.b))
return(den)
}
propos_b.j.x = function(beta, f.j.x, d.j.x, sigmaS.b){
mu = mu.j.x(beta, f.j.x, d.j.x)
return(rlogitnorm(1, mu, sqrt(sigmaS.b)))
}
#---------
#------------------------------------------
# Reaction time conditional posteriors. ******
#------------------------------------------
post_alpha = function(sigmaS.delta, alpha.X){
mu = (X + sigmaS.delta/sigma.alpha)^(-2) *sum(alpha.X)
sig = (X + sigmaS.delta/sigma.alpha)^(-2) * sigmaS.delta
return(rnorm(1, mu, sqrt(sig)))
}
post_sigmaS.delta = function(alpha, alpha.X){
ad = a.delta + X/2
bd = b.delta + .5 * sum((alpha.X-alpha)^2)
return(rinvgauss(1, ad, bd))
}
# Note a.t is sampled using MH
# The posterior returns a density instead of a sample.
# the sample is taken from the proposal
post_a.t = function(x, a.t, b.t){
den = dlnorm(x, mu.a,sigma.a) * prod(rep(dinvgauss(x, a.t, b.t)),X)
return(den)
}
propos_a.t = function(prev){
return(rlnorm(1,prev, .2))
}
post_b.t = function(a.t, tau.X){
kd = k.b + X * a.t
thetad = (theta.b^(-1) + sum(tau.X^(-1)) )^(-1)
return(rgamma(1, kd, thetad))
}
post_alpha.x = function(M.x, tauS.x, sigmaS.delta, S.x){
mud = (M.x + tauS.x / sigmaS.delta)^(-1) * sum(log(S.x))
sigd = (M.x + tauS.x / sigmaS.delta)^(-1) * tauS.x
return(rnorm(1, mud, sqrt(sigd)))
}
post_tauS.x = function(a.t, b.t, M.x, S.x, alpha.x){
ad = a.t + M.x/2
bd = b.t + .5 * sum((log(S.x)-alpha.x)^2)
return(rinvgauss(1, ad, bd))
}
#----------------------------------------------------------
#----------------------------------------------------------
#------------------------------------
# INPUT DATA from observations
X = 52 # the total number of root users
J = vector(length=X) # where J_x is the number of retweets user x got including
# them.
N = sum(J) # the total number of observed reaction time for all training and
# predictions tweets.
f = vector(length = N) # the number of followers of user
d = vector(length = N)
S = vector(length = N)
M = vector(length = X)
library('./model.R')
source('D:/concordia/winter21/graphical models/project/src/models.R')
library('./model.R')
library('models.R')
library('./models.R')
library('./models')
source('./models.R')
betas = c(NA,NA,NA)
sigmaS.b = NA
b.J.X = vector(length = sum(J))
#---------------
alpha = NA
sigmaS.delta = NA
a.t = NA
b.t = NA
alpha.X = vector(length = X)
tauS.X = vector(length = X)
#-------------
n = 500 # number of samples to be taken from each parameter
#---------
sam_betas = array(NA, dim=c(n,3))
sam_sigmaS.b = vector(length=n)
sam_b = array(NA, dim=c(n,sum(J)))
#----------------------
sam_alpha= vector(length = n)
sam_sigmaS.delta = vector(length = n)
sam_a.t = vector(length = n)
sam_b.t = vector(length = n)
sam_alpha = array(NA, dim=c(n,X))
sam_tauS = array(NA, dim=c(n,X))
source('./models.R')
J
J[1:3]
J[0:3]
J[0:3] == J[1,3]
J[0:3] == J[1:3]
x = runif(6)
x[1:3]
x[0:3]
x[0]
x[0]+1
x[x[0]+1]
x[x[0]+1:3]
x[(x[0]+1):3]
x
x[(x[1]+1):3]
x[(x[0]+1):3]
#------------------------------------
# INPUT DATA from observations
model_input = readRDS('../data/model_input.rds')
X = model_input$X # the total number of root users
J = model_input$J # where J_x is the number of retweets user x got including
# them.
JCUM = model_input$JCUM
N = model_input$N # the total number of observed reaction time for all training and
# predictions tweets.
f = model_input$f # the number of followers of user
d = model_input$d
S = model_input$S
M = model_input$M
source('./models.R')
betas = c(NA,NA,NA)
sigmaS.b = NA
b.J.X = vector(length = sum(J))
#---------------
alpha = NA
sigmaS.delta = NA
a.t = NA
b.t = NA
alpha.X = vector(length = X)
tauS.X = vector(length = X)
#-------------
n = 500 # number of samples to be taken from each parameter
#---------
sam_betas = array(NA, dim=c(n,3))
sam_sigmaS.b = vector(length=n)
sam_b = array(NA, dim=c(n,sum(J)))
#----------------------
sam_alpha= vector(length = n)
sam_sigmaS.delta = vector(length = n)
sam_a.t = vector(length = n)
sam_b.t = vector(length = n)
sam_alpha = array(NA, dim=c(n,X))
sam_tauS = array(NA, dim=c(n,X))
#-------------------------------------------------
#------------------------------------------------
# Initialization ::
# Intialize each according to its prior distribution.
betas = prior_beta()
sigmaS.b = prior_sigmaS.b()
for(i in 1:N){
muj = mu.j.x(betas, f[i], d[i])
b.J.X[i] = prior_b.j.x(muj, sigmaS.b)
}
alpha = prior_alpha()
sigmaS.delta = prior_sigmaS.delta()
a.t = prior_a.t()
b.t = prior_b.t()
sigmaS.delta = prior_sigmaS.delta()
a.t = prior_a.t()
b.t = prior_b.t()
alpha = prior_alpha()
b.J.X[i] = prior_b.j.x(muj, sigmaS.b)
for(i in 1:N){
muj = mu.j.x(betas, f[i], d[i])
b.J.X[i] = prior_b.j.x(muj, sigmaS.b)
}
muj = mu.j.x(betas, f[i], d[i])
setwd("D:/concordia/winter21/graphical models/project/bayesian-retweet-count-model/src")
source('./models.R')
betas = c(NA,NA,NA)
sigmaS.b = NA
b.J.X = vector(length = sum(J))
#---------------
alpha = NA
sigmaS.delta = NA
a.t = NA
b.t = NA
alpha.X = vector(length = X)
tauS.X = vector(length = X)
#-------------
n = 500 # number of samples to be taken from each parameter
#---------
sam_betas = array(NA, dim=c(n,3))
sam_sigmaS.b = vector(length=n)
sam_b = array(NA, dim=c(n,sum(J)))
#----------------------
sam_alpha= vector(length = n)
sam_sigmaS.delta = vector(length = n)
sam_a.t = vector(length = n)
sam_b.t = vector(length = n)
sam_alpha = array(NA, dim=c(n,X))
sam_tauS = array(NA, dim=c(n,X))
betas = prior_beta()
sigmaS.b = prior_sigmaS.b()
betas
i=2
f[2]
d[2]
f
source('./models.R')
muj = mu.j.x(betas, f[i], d[i])
for(i in 1:N){
muj = mu.j.x(betas, f[i], d[i])
b.J.X[i] = prior_b.j.x(muj, sigmaS.b)
}
b.J.X
alpha = prior_alpha()
sigmaS.delta = prior_sigmaS.delta()
a.t = prior_a.t()
b.t = prior_b.t()
for(i in 1:X){
alpha.X[i] = prior_alpha.x(alpha, sigmaS.delta)
}
for(i in 1:X){
tauS.X[i] = prior_tauS.x(a.t, b.t)
}
sam_betas[1,] = betas
sam_sigmaS.b[1] = sigmaS.b
sam_b[1,] = b.J.X
sam_alpha[1] = alpha
sam_sigmaS.delta[1] = sigmaS.delta
sam_a.t[1] = a.t
sam_b.t[1] = b.t
sam_alpha[1,] = alpha.X
sam_tauS[1,] = tauS.X
for(t in 1:n){
# Here for each time step, we sample each parameter once,
# Note that a.t and b.j.x are sampled using MH
betas = post_beta(sigmaS.b, b.J.X)
sigmaS.b = post_sigmaS.b(b.J.X, beta)
for(i in 1:N){
prob = 2
while(runif(1) > prob){
# newp ~ Q(p|p')
newp = propos_b.j.x(betas, f[i], d[i], sigmaS.b)
# probability of acceptance = p(p)/p(p')
prob = post_b.j.x(newp, f[i], b.J.X[i], d[i], betas, sigmaS.b) /
post_b.j.x(b.J.X[i], f[i], b.J.X[i], d[i], betas, sigmaS.b)
}
b.J.X[i] = newp
}
alpha = post_alpha(sigmaS.delta, alpha.X)
sigmaS.delta= post_sigmaS.delta(alpha, alpha.X)
prob = 2
while(runif(1) > prob){
newa = propos_a.t(a.t)
prob = post_a.t(newa,a.t, b.t, tauS.X) / post_a.t(a.t,a.t,b.t,tauS.X)
}
a.t = newa
b.t = post_b.t(a.t,tauS.X)
alpha.X[1] = post_alpha.x(M[1], tauS.X[1], sigmaS.delta, S.x[1:JCUM[1]])
for(i in 2:X){
alpha.X[i] = post_alpha.x(M[i], tauS.X[i], sigmaS.delta,
S.x[(JCUM[i-1]+1):JCUM[i]])
}
tauS.X[1] = post_tauS.x(a.t, b.t, M[1],S.x[1:JCUM[1]],
alpha.X[1])
for(i in 2:X){
tauS.X[i] = post_tauS.x(a.t, b.t, M[i],S.x[(JCUM[i-1]+1):JCUM[i]],
alpha.X[i])
}
#----------------
# we append the new samples to the arrays.
sam_betas[t,] = betas
sam_sigmaS.b[t] = sigmaS.b
sam_b[t,] = b.J.X
sam_alpha[t] = alpha
sam_sigmaS.delta[t] = sigmaS.delta
sam_a.t[t] = a.t
sam_b.t[t] = b.t
sam_alpha[t,] = alpha.X
sam_tauS[t,] = tauS.X
}
C
b = b.J.X
# The conditional joint posterior of the three betas.
# The follow a multivariate normal distribution with parameters mu and C
# as defined below.
N1 = N + sigmaS.b * sigma.beta^(-2)
E = sum(log(f+1)*log(d+1))
D = sum(log(d+1))
D2 = sum(log(d+1)^2) + sigmaS.b * sigma.beta^(-2)
W = sum(log(f+1))
W2 = sum(log(f+1)^2) + sigmaS.b * sigma.beta^(-2)
Y0 = sum(log(b+1))
YF = sum(log(b+1)*log(f+1))
Yd = sum((log(b+1)^2)*log(d+1)) + sigmaS.b * sigma.beta^(-2)
CM = matrix(c(
N1, W, D,
W, W2, E,
D, E, D2),nrow=3,byrow = TRUE)
CM = sigmaS.b * solve(CM)
CM
C %*% t(c(Y0, YF, Yd))
CM %*% t(c(Y0, YF, Yd))
CM %*% c(Y0, YF, Yd)
rmvnorm(1, mu, CM)
mu = CM %*% c(Y0, YF, Yd)
rmvnorm(1, mu, CM)
# Here for each time step, we sample each parameter once,
# Note that a.t and b.j.x are sampled using MH
betas = post_beta(sigmaS.b, b.J.X)
source('./models.R')
# Here for each time step, we sample each parameter once,
# Note that a.t and b.j.x are sampled using MH
betas = post_beta(sigmaS.b, b.J.X)
sigmaS.b = post_sigmaS.b(b.J.X, beta)
betas
c(betas)
c(rmvnorm(1, rep(mu.beta,3), diag(rep(sigma.beta,3))))
sigmaS.b = post_sigmaS.b(b.J.X, beta)
source('./models.R')
sigmaS.b = post_sigmaS.b(b.J.X, beta)
beta[1]
betas[1]
sigmaS.b = post_sigmaS.b(b.J.X, betas)
for(i in 1:N){
prob = 2
while(runif(1) > prob){
# newp ~ Q(p|p')
newp = propos_b.j.x(betas, f[i], d[i], sigmaS.b)
# probability of acceptance = p(p)/p(p')
prob = post_b.j.x(newp, f[i], b.J.X[i], d[i], betas, sigmaS.b) /
post_b.j.x(b.J.X[i], f[i], b.J.X[i], d[i], betas, sigmaS.b)
}
b.J.X[i] = newp
}
for(i in 1:N){
prob = 0
while(runif(1) > prob){
# newp ~ Q(p|p')
newp = propos_b.j.x(betas, f[i], d[i], sigmaS.b)
# probability of acceptance = p(p)/p(p')
prob = post_b.j.x(newp, f[i], b.J.X[i], d[i], betas, sigmaS.b) /
post_b.j.x(b.J.X[i], f[i], b.J.X[i], d[i], betas, sigmaS.b)
}
b.J.X[i] = newp
}
b.J.X
f
prob
post_b.j.x(b.J.X[i], f[i], b.J.X[i], d[i], betas, sigmaS.b)
post_b.j.x(newp, f[i], b.J.X[i], d[i], betas, sigmaS.b)
propos_b.j.x(betas, f[i], d[i], sigmaS.b)
b.J.X
dbinom(M[1],f.j.x, p.j.x)
dbinom(M[1],23,.2)
source('./models.R')
for(i in 1:N){
prob = 0
while(runif(1) > prob){
# newp ~ Q(p|p')
newp = propos_b.j.x(betas, f[i], d[i], sigmaS.b)
# probability of acceptance = p(p)/p(p')
prob = post_b.j.x(newp,M[i], f[i], d[i], betas, sigmaS.b) /
post_b.j.x(b.J.X[i],M[i], f[i], d[i], betas, sigmaS.b)
}
b.J.X[i] = newp
}
i=1
propos_b.j.x(betas, f[i], d[i], sigmaS.b)
newp
prob
post_b.j.x(newp,M[i], f[i], d[i], betas, sigmaS.b)
post_b.j.x(b.J.X[i],M[i], f[i], d[i], betas, sigmaS.b)
M[i]
f[i]
d[i]
dbinom(21, 87039, newp)
dbinom(21, 87039, 123123)
dbinom(21, 87039, 1231)
dbinom(21, 87039, .05)
dbinom(21, 87039, .15)
dbinom(21, 87039, 1)
dbinom(21, 87039, .05)
dbinom(211, 87039, .05)
dbinom(21111, 87039, .05)
dbinom(87039, 87039, .05)
dbinom(87039, 87039, 1)
dbinom(87039, 87039, .5)
dbinom(2,4,.5)
fit = stan('./stan_model.stan', data=model_input,
iter = 7000, warmup=1000, chains=3)
require(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
data = readRDS('../data/model_input.rds')
model_input = list(
X = data$X, # the total number of root users
J = data$J, # where J_x is the number of retweets user x got including
# them.
JCUM = data$JCUM,
N = data$N, # the total number of observed reaction time for all training and
# predictions tweets.
f = data$root_f, # the number of followers of user
d = data$d,
S = data$S,
M = data$M)
fit = stan('./stan_model.stan', data=model_input,
iter = 7000, warmup=1000, chains=3)
la <- extract(fit, permuted = TRUE)
View(la)
View(la)
apply(la$beta, 1, mean)
apply(la$beta, 2, mean)
apply(la$b, 2, mean)
apply(la$sigmaS_b, 2, mean)
apply(la$sigmaS_b, 1, mean)
mean(la$sigmaS_b)
apply(la$beta, 2, mean)
fit = stan('./stan_model.stan', data=model_input,
iter = 50000, warmup=5000, chains=3)
la <- extract(fit, permuted = TRUE)
lab <- lab
lab <- la
View(la)
apply(la$beta, 2, mean)
apply(la$b, 2, mean)
save(la, '../output/la1.rda')
save(la,file= '../output/la1.rda')
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
rstan:::rstudio_stanc("stan_model.stan")
fit = stan('./stan_model.stan', data=model_input,
iter = 5000, warmup=1000, chains=3)
la <- extract(fit, permuted = TRUE)
View(data)
rstan:::rstudio_stanc("stan_model.stan")
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
c_light <- c("#DCBCBC")
c_light_highlight <- c("#C79999")
c_mid <- c("#B97C7C")
c_mid_highlight <- c("#A25050")
c_dark <- c("#8F2727")
c_dark_highlight <- c("#7C0000")
schools_dat <- list(J = 8,
y = c(28,  8, -3,  7, -1,  1, 18, 12),
sigma = c(15, 10, 16, 11,  9, 11, 10, 18))
fit <- stan(file = './stan_tutorial.stan', data = schools_dat,
iter=1200, warmup=500, chains=1, seed=14, refresh=1200)
require(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
data = readRDS('../data/model_input.rds')
model_input = list(
X = data$X, # the total number of root users
J = data$J, # where J_x is the number of retweets user x got including
# them.
JCUM = data$JCUM,
N = data$N, # the total number of observed reaction time for all training and
# predictions tweets.
f = data$root_f, # the number of followers of user
d = data$d,
S = data$S,
M = data$M)
fit = stan('./stan_model.stan', data=model_input,
iter = 5000, warmup=1000, chains=3)
install.packages(twitter)
install.packages("twitter")
install.packages("twitterR")
install.packages("twitteR")
